{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9q95w0whp9h7nprw+GKBP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/songulonur/pratik-derin-ogrenme-uygulamalari/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "bnAHr1-6RlK2",
        "outputId": "39631034-c6c9-4f76-80b2-f1909e4c883c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-c7830f59572b>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    Erişimi olanlar\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "rakam_tanima_CNN_MNIST\n",
        "Erişimi olanlar\n",
        "Paylaşılmıyor\n",
        "Sistem özellikleri\n",
        "Tür\n",
        "Metin\n",
        "Boyut\n",
        "4 KB\n",
        "Kullanılan depolama alanı\n",
        "4 KB\n",
        "Konum\n",
        "derinogrenme\n",
        "Sahibi\n",
        "ben\n",
        "Değiştirilme:\n",
        "16:13 tarihinde benim tarafımdan\n",
        "Açıldı\n",
        "16:15 tarihinde benim tarafımdan\n",
        "Oluşturulma tarihi\n",
        "16:12 tarihinde Google Drive Web ile\n",
        "Açıklama·ekleyin\n",
        "Görüntüleyenler indirebilir\n",
        "# -*- coding: utf-8 -*- \n",
        "'''\n",
        "Deep Learning Türkiye topluluğu tarafından hazırlanmıştır.\n",
        "\n",
        "Amaç: El yazısı rakamların tanınması.\n",
        "Veriseti: MNIST (http://yann.lecun.com/exdb/mnist/)\n",
        "Algoritma: Evrişimli Sinir Ağları (Convolutional Neural Networks)\n",
        "Microsoft Azure Notebook: https://notebooks.azure.com/deeplearningturkiye/libraries/pratik-derin-ogrenme/html/rakam_tanima_CNN_MNIST.ipynb\n",
        "\n",
        "Ağ Mimarisi:\n",
        "\n",
        "- 32 x 3 x 3 CONV\n",
        "- 64 x 3 x 4 CONV\n",
        "- 2 x 2 MAX POOL\n",
        "- DROPOUT (%25)\n",
        "- 128 FC\n",
        "- DROPOUT (%50)\n",
        "- 10 FC\n",
        "\n",
        "\n",
        "12 epoch sonunda 99.25% test doğruluk oranı elde ediliyor.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from tensorflow.keras import utils as np_utils\n",
        "import tensorflow as tf \n",
        "\n",
        "batch_size = 128 # her bir iterasyonda \"128\" resim alınsın\n",
        "num_classes = 10 # ayırt etmek istediğimiz \"10\" rakam\n",
        "epochs = 12 # eğitim 12 epoch sürsün\n",
        "\n",
        "# giriş resimlerinin boyutları 28 x 28 piksel\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# veri önce karıştırılıyor (shuffle) sonra da eğitim/test diye ayrılıyor\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# sınıf vektörleri ikili (binary) formununa dönüştürülür\n",
        "# \"to_catogorical\" fonksiyonu ile one-hot-encoding yapıyoruz\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 3x3 boyutunda 32 adet filtreden oluşan ReLU aktivasyonlu CONV katmanı ekleyelim. \n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "\n",
        "# 3x3 boyutunda 64 adet filtreden oluşan ReLU aktivasyonlu CONV katmanı ekleyelim. \n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# 2x2 boyutlu çerçeveden oluşan MAXPOOL katmanı ekleyelim. \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# her seferinde nöronların %25'i atılsın (drop)\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Tam bağlantılı (fully connected) katmanına geçiş olacağı için düzleştirme yapalım \n",
        "model.add(Flatten())\n",
        "\n",
        "# 128 nörondan oluşan ReLU aktivasyonu FC katmanı ekleyelim \n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Her seferinde %50'sini atalım (drop)\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Çıkış katmanına sınıf sayısı kadar (10) Softmax aktivasyonlu nöron ekleyelim\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Adadelta optimizasyon yöntemini ve cross entropy yitim (loss) fonksiyonunu kullanalım.\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# eğitim işlemini gerçekleştirelim\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "# test işlemini gerçekleştirelim ve sonuçları ekrana yazdıralım\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    }
  ]
}